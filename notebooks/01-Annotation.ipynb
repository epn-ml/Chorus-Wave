{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "\n",
    "# \"\"\"Notebook for rapid prompt-based annotation. Box to mask using Segment Anything Model\"\"\"\n",
    "\n",
    "# __author__      = \"Sahib Julka <sahib.julka@uni-passau.de>\"\n",
    "# __copyright__   = \"GPL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from utils import encode_image\n",
    "from jupyter_bbox_widget import BBoxWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "CHECKPOINT_PATH = os.path.join(\"sam\",\"sam_vit_h_4b8939.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "mask_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'processed/images'\n",
    "IMAGES = []\n",
    "filenames = []\n",
    "for fn in os.listdir(DATA_PATH):\n",
    "    if fn.endswith('chorus1_psd.png'):\n",
    "        filenames.append(fn)\n",
    "        IMAGES.append(os.path.join(DATA_PATH, fn))\n",
    "        \n",
    "        #widget.image = encode_image(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec30e7d935e4bf9bf4b68cc8877d40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BBoxWidget(colors=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bâ€¦"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.randint(1, len(filenames))\n",
    "widget = BBoxWidget()\n",
    "widget.image = encode_image(IMAGES[i])\n",
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 22, 'y': 162, 'width': 78, 'height': 175, 'label': ''},\n",
       " {'x': 132, 'y': 206, 'width': 111, 'height': 131, 'label': ''},\n",
       " {'x': 281, 'y': 182, 'width': 153, 'height': 157, 'label': ''},\n",
       " {'x': 468, 'y': 184, 'width': 112, 'height': 125, 'label': ''},\n",
       " {'x': 602, 'y': 166, 'width': 201, 'height': 161, 'label': ''},\n",
       " {'x': 835, 'y': 176, 'width': 246, 'height': 155, 'label': ''},\n",
       " {'x': 1129, 'y': 170, 'width': 114, 'height': 153, 'label': ''},\n",
       " {'x': 1312, 'y': 174, 'width': 56, 'height': 169, 'label': ''},\n",
       " {'x': 1386, 'y': 180, 'width': 30, 'height': 105, 'label': ''},\n",
       " {'x': 1428, 'y': 164, 'width': 34, 'height': 149, 'label': ''},\n",
       " {'x': 1523, 'y': 150, 'width': 393, 'height': 169, 'label': ''},\n",
       " {'x': 1482, 'y': 235, 'width': 25, 'height': 88, 'label': ''},\n",
       " {'x': 1269, 'y': 273, 'width': 25, 'height': 78, 'label': ''},\n",
       " {'x': 1271, 'y': 182, 'width': 27, 'height': 53, 'label': ''},\n",
       " {'x': 1490, 'y': 162, 'width': 25, 'height': 40, 'label': ''}]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widget.bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# default_box is going to be used if you will not draw any box on image above\n",
    "default_box = {'x': 68, 'y': 247, 'width': 555, 'height': 678, 'label': ''}\n",
    "boxes = []\n",
    "#box = widget.bboxes[0] if widget.bboxes else default_box\n",
    "for box in widget.bboxes:\n",
    "    box = np.array([\n",
    "        box['x'], \n",
    "        box['y'], \n",
    "        box['x'] + box['width'], \n",
    "        box['y'] + box['height']\n",
    "    ])\n",
    "    boxes.append(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "boxes = np.array(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1, 256, 256] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[374], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m mask_predictor\u001b[38;5;241m.\u001b[39mset_image(image_rgb)\n\u001b[1;32m     11\u001b[0m transformed_boxes \u001b[38;5;241m=\u001b[39m mask_predictor\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mapply_boxes_torch(boxes, image_rgb\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m masks, scores, logits \u001b[38;5;241m=\u001b[39m mask_predictor\u001b[38;5;241m.\u001b[39mpredict_torch(\n\u001b[1;32m     15\u001b[0m     point_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     point_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     boxes\u001b[38;5;241m=\u001b[39mtransformed_boxes,\n\u001b[1;32m     18\u001b[0m     multimask_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m mask \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/envs/segment_anything/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/segment_anything/lib/python3.11/site-packages/segment_anything/predictor.py:229\u001b[0m, in \u001b[0;36mSamPredictor.predict_torch\u001b[0;34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001b[0m\n\u001b[1;32m    222\u001b[0m sparse_embeddings, dense_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprompt_encoder(\n\u001b[1;32m    223\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m    224\u001b[0m     boxes\u001b[38;5;241m=\u001b[39mboxes,\n\u001b[1;32m    225\u001b[0m     masks\u001b[38;5;241m=\u001b[39mmask_input,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Predict masks\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m low_res_masks, iou_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmask_decoder(\n\u001b[1;32m    230\u001b[0m     image_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,\n\u001b[1;32m    231\u001b[0m     image_pe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprompt_encoder\u001b[38;5;241m.\u001b[39mget_dense_pe(),\n\u001b[1;32m    232\u001b[0m     sparse_prompt_embeddings\u001b[38;5;241m=\u001b[39msparse_embeddings,\n\u001b[1;32m    233\u001b[0m     dense_prompt_embeddings\u001b[38;5;241m=\u001b[39mdense_embeddings,\n\u001b[1;32m    234\u001b[0m     multimask_output\u001b[38;5;241m=\u001b[39mmultimask_output,\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Upscale the masks to the original image resolution\u001b[39;00m\n\u001b[1;32m    238\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpostprocess_masks(low_res_masks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_size)\n",
      "File \u001b[0;32m/opt/conda/envs/segment_anything/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/segment_anything/lib/python3.11/site-packages/segment_anything/modeling/mask_decoder.py:94\u001b[0m, in \u001b[0;36mMaskDecoder.forward\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     73\u001b[0m     image_embeddings: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     multimask_output: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     78\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Predict masks given image and prompt embeddings.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m      torch.Tensor: batched predictions of mask quality\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     masks, iou_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_masks(\n\u001b[1;32m     95\u001b[0m         image_embeddings\u001b[38;5;241m=\u001b[39mimage_embeddings,\n\u001b[1;32m     96\u001b[0m         image_pe\u001b[38;5;241m=\u001b[39mimage_pe,\n\u001b[1;32m     97\u001b[0m         sparse_prompt_embeddings\u001b[38;5;241m=\u001b[39msparse_prompt_embeddings,\n\u001b[1;32m     98\u001b[0m         dense_prompt_embeddings\u001b[38;5;241m=\u001b[39mdense_prompt_embeddings,\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Select the correct mask or masks for output\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multimask_output:\n",
      "File \u001b[0;32m/opt/conda/envs/segment_anything/lib/python3.11/site-packages/segment_anything/modeling/mask_decoder.py:144\u001b[0m, in \u001b[0;36mMaskDecoder.predict_masks\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings)\u001b[0m\n\u001b[1;32m    142\u001b[0m hyper_in \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(hyper_in_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    143\u001b[0m b, c, h, w \u001b[38;5;241m=\u001b[39m upscaled_embedding\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 144\u001b[0m masks \u001b[38;5;241m=\u001b[39m (hyper_in \u001b[38;5;241m@\u001b[39m upscaled_embedding\u001b[38;5;241m.\u001b[39mview(b, c, h \u001b[38;5;241m*\u001b[39m w))\u001b[38;5;241m.\u001b[39mview(b, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, h, w)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Generate mask quality predictions\u001b[39;00m\n\u001b[1;32m    147\u001b[0m iou_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miou_prediction_head(iou_token_out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1, 256, 256] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "\n",
    "boxes = torch.Tensor(boxes).to(DEVICE)\n",
    "image_bgr = cv2.imread(IMAGES[i])\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask_predictor.set_image(image_rgb)\n",
    "transformed_boxes = mask_predictor.transform.apply_boxes_torch(boxes, image_rgb.shape[:2])\n",
    "\n",
    "\n",
    "masks, scores, logits = mask_predictor.predict_torch(\n",
    "    point_coords = None,\n",
    "    point_labels = None,\n",
    "    boxes=transformed_boxes,\n",
    "    multimask_output=False\n",
    ")\n",
    "mask = masks.sum(axis = 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator(color=sv.Color.red())\n",
    "mask_annotator = sv.MaskAnnotator(color=sv.Color.red())\n",
    "\n",
    "detections = sv.Detections(\n",
    "    xyxy=sv.mask_to_xyxy(masks=mask),\n",
    "    mask=mask\n",
    ")\n",
    "detections = detections[detections.area == np.max(detections.area)]\n",
    "\n",
    "source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections, skip_label=True)\n",
    "segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=[source_image, segmented_image],\n",
    "    grid_size=(1, 2),\n",
    "    titles=['source image', 'segmented image']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import supervision as v\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=mask,\n",
    "    grid_size=(1, 4),\n",
    "    size=(16, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"processed/masks+/\", exist_ok = True)\n",
    "np.save('processed/masks+/{}.npy'.format(filenames[i].split('.png')[0]), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segment_anything] *",
   "language": "python",
   "name": "conda-env-segment_anything-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
